{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980dd67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31bed5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "device_dict={\"S\":\"Smartphone\", \n",
    "             \"T\":\"Tablet\",\n",
    "             \"L\":\"Laptop\",\n",
    "             \"V\":\"VehicleLCD\",\n",
    "             \"M\":\"Monitor\"}\n",
    "status_dict={\"F\":\"Focus\"}\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "factor = 360*10 # In fact, we need to take acount of focal length, pixel scale, and distortion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab440b39",
   "metadata": {},
   "source": [
    "PCN에 영상파일 이름 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b2fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "nia_dir = \"/run/user/1000/gvfs/sftp:host=pcndev.co.kr,port=10200/AIDATA/\"\n",
    "ddir1 = \"/media/di/data/NIA2022/\"\n",
    "\n",
    "for date in [26,29,30,31]:\n",
    "    wdir = nia_dir+f'08{date:02d}/processing/S1/'\n",
    "\n",
    "    flist = glob(wdir+\"0??/T1/*/RGB/*_rgb_*.mp4\")\n",
    "    flist.sort()\n",
    "    print(len(flist))\n",
    "    # .mp4 파일명 수정\n",
    "    # .csv도 필요하면 적용\n",
    "    # mp4 먼저 고치고 나머지 처리하면 csv 파일 이름 변경할 필요 없음. \n",
    "    for fncsv in flist:\n",
    "        fnew = fncsv.replace(\"_K_\", \"_T_\")\n",
    "        if fnew != fncsv:\n",
    "            shutil.move(fncsv, fnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a04b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79abac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/syn2422/raw/raw/0913/newprocessing/processing/S1/']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = \"/mnt/syn2422/raw/raw/\"\n",
    "date = \"0913\"\n",
    "glob(base_dir+f'{date}/newprocessing/processing/S1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de587621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e1a4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/RGB/NIA22EYE_S1_056_T1_S06_L_rgb_A_D_T.mp4'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee9a8140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_A_U_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_D_C_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_D_D_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_D_E_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_D_F_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_D_T_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_D_U_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_F_C_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_F_D_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_F_E_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_F_F_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_F_H_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_F_T_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_F_U_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_N_D_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_N_E_T.csv done\n",
      "/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/NIA22EYE_S1_056_T1_S06_L_head_N_F_T.csv done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Get the result\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mface_mesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# To improve performance\u001b[39;00m\n\u001b[1;32m     64\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/site-packages/mediapipe/python/solutions/face_mesh.py:124\u001b[0m, in \u001b[0;36mFaceMesh.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the face landmarks on each detected face.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    face landmarks on each detected face.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/site-packages/mediapipe/python/solution_base.py:367\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mwait_until_idle()\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcollections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamedtuple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSolutionOutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_stream_type_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    370\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m stream_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_outputs:\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/collections/__init__.py:414\u001b[0m, in \u001b[0;36mnamedtuple\u001b[0;34m(typename, field_names, rename, defaults, module)\u001b[0m\n\u001b[1;32m    408\u001b[0m namespace \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_tuple_new\u001b[39m\u001b[38;5;124m'\u001b[39m: tuple_new,\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__builtins__\u001b[39m\u001b[38;5;124m'\u001b[39m: {},\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamedtuple_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    412\u001b[0m }\n\u001b[1;32m    413\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda _cls, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: _tuple_new(_cls, (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m))\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;21m__new__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;21m__new__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__new__\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;21m__new__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreate new instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_dir = [\"/mnt/syn2422/raw/raw/\",\n",
    "           \"/media/di/mx500_2tb2/NIA2022_2/\"][0]\n",
    "\n",
    "for date in [\"0913\"]:\n",
    "    wdir = base_dir+f'{date}/processing/S1/'\n",
    "\n",
    "    flist = glob(wdir+\"0??/T1/*/RGB/*_rgb_*.mp4\")\n",
    "    flist.sort()\n",
    "    print(len(flist))\n",
    "    # .mp4 파일명 수정\n",
    "    # .csv도 필요하면 적용\n",
    "    # mp4 먼저 고치고 나머지 처리하면 csv 파일 이름 변경할 필요 없음. \n",
    "    for fncsv in flist:\n",
    "        fnew = fncsv.replace(\"_K_\", \"_T_\")\n",
    "        if fnew != fncsv:\n",
    "            shutil.move(fncsv, fnew)\n",
    "            \n",
    "    # 수정된 이름으로 다시 \n",
    "    flist = glob(wdir+\"0??/T1/*/RGB/*_rgb_*.mp4\")\n",
    "    flist.sort()\n",
    "    for iin, fn in enumerate(flist):\n",
    "        #fn.replace(\"processing\")\n",
    "        out_dir = fn.split(\"NIA22EYE\")[0]\n",
    "        fn_ = fn.split(\"/\")[-1]\n",
    "\n",
    "        _, _, ID, _, scenario, device, imgtype, status, action, orientation = fn_.split(\"_\")\n",
    "        orientation = orientation.split(\".mp4\")[0]\n",
    "\n",
    "        new_dir = out_dir.replace(\"RGB/\", \"FaceAngle/\")\n",
    "\n",
    "        if not os.path.isdir(new_dir):\n",
    "            os.mkdir(new_dir)\n",
    "\n",
    "        fn_out = fn_.replace(\"rgb\", \"head\")\n",
    "        fn_out = fn_out.replace(\".mp4\", \".csv\")\n",
    "        \n",
    "        if os.path.isfile(new_dir+fn_out) and os.path.getsize(new_dir+fn_out) > 40:\n",
    "            print(\"pass\")\n",
    "            continue\n",
    "\n",
    "        cap = cv2.VideoCapture(fn)    \n",
    "        nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        arr = np.zeros(nframes, dtype=[(\"roll\", float), \n",
    "                                       (\"pitch\", float),\n",
    "                                       (\"yaw\", float)])\n",
    "        i = 0\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # Flip the image horizontally for a later selfie-view display\n",
    "            # Also convert the color space from BGR to RGB\n",
    "            image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # To improve performance\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Get the result\n",
    "            results = face_mesh.process(image)\n",
    "\n",
    "            # To improve performance\n",
    "            image.flags.writeable = True\n",
    "\n",
    "            # Convert the color space from RGB to BGR\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            img_h, img_w, img_c = image.shape\n",
    "            face_3d = []\n",
    "            face_2d = []\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                        if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                            if idx == 1:\n",
    "                                nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                                nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * img_w)\n",
    "\n",
    "                            x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                            # Get the 2D Coordinates\n",
    "                            face_2d.append([x, y])\n",
    "\n",
    "                            # Get the 3D Coordinates\n",
    "                            face_3d.append([x, y, lm.z])       \n",
    "\n",
    "                    # Convert it to the NumPy array\n",
    "                    face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "                    # Convert it to the NumPy array\n",
    "                    face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "                    # The camera matrix\n",
    "                    focal_length = 1 * img_w\n",
    "\n",
    "                    cam_matrix = np.array([ [focal_length, 0, img_h / 2],\n",
    "                                            [0, focal_length, img_w / 2],\n",
    "                                            [0, 0, 1]])\n",
    "\n",
    "                    # The Distortion Matrix\n",
    "                    dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "                    # Solve PnP\n",
    "                    success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "                    # Get rotational matrix\n",
    "                    rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "                    # Get angles\n",
    "                    angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "                    arr['roll'][i]  = angles[0]\n",
    "                    arr['pitch'][i] = angles[1]\n",
    "                    arr['yaw'][i]   = angles[2]\n",
    "\n",
    "            i+=1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # temp\n",
    "        arr['roll'] -= np.mean(arr['roll'][5::100])\n",
    "        arr['pitch'] -= np.mean(arr['pitch'][5::100])\n",
    "        for field in ['roll', 'pitch', 'yaw']:\n",
    "            ind = np.where(arr[field]!=0)[0]\n",
    "            if len(ind) < 2:\n",
    "                print(\"No valid points\", len(ind))\n",
    "                break\n",
    "            elif len(ind) < len(arr):\n",
    "                f = interp1d(ind, arr[field][ind])\n",
    "                arr[field] = f(np.linspace(min(ind),max(ind), len(arr)))\n",
    "                print(\"Interpolated\")\n",
    "\n",
    "        arr[\"roll\"] *= factor\n",
    "        arr[\"pitch\"] *= factor\n",
    "        arr[\"yaw\"] *= factor\n",
    "\n",
    "\n",
    "        with open(new_dir+fn_out, \"w\") as f:\n",
    "            f.write(\"[head angle] roll      pitch      yaw\\n\")\n",
    "            for roll, pitch, yaw in arr:\n",
    "                f.write(f\"{roll:.4f}, {pitch:.4f}, {yaw:.4f}\\n\")\n",
    "\n",
    "        print(new_dir+fn_out, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d571e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/syn2422/raw/raw/0913/processing/S1/056/T1/Laptop/FaceAngle/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
