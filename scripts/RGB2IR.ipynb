{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e50a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d25f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 \n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import ritnet\n",
    "import nia22\n",
    "from glob import glob\n",
    "\n",
    "from nia22 import scenario\n",
    "from nia22.mask_utils import gen_mask\n",
    "from nia22.eyes import Eye, device_dict, draw_two_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe656914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52874626",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = '/home/hoseung/Work/NIA/data/jsons/'\n",
    "vid_dir_base = '/home/hoseung/Work/NIA/data/run/by_id/'\n",
    "#ddir = \"/home/di/Work/data1/NIA2022/ORG/\"\n",
    "#vid_dir_base = \"/mnt/syn2422/raw/raw/by_id/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa85e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_scenario(uid, devices = [\"V\", \"M\"]):\n",
    "    if not isinstance(uid, str): uid = f\"{uid:03d}\"\n",
    "    pattern = ddir + f\"{uid}/*.json\"\n",
    "    json_list = glob(pattern)\n",
    "    json_list.sort()\n",
    "    print(f\"{len(json_list)} JSON files are found\")\n",
    "    \n",
    "    ####\n",
    "    all_scenarios = []\n",
    "    for jl in json_list:\n",
    "        jj = jl.split(\"/\")[-1]\n",
    "        device = jj.split(\"_\")[5]\n",
    "        code = jj[-14:-9]\n",
    "        if device in devices:\n",
    "        #if True:\n",
    "            all_scenarios.append((device, code))\n",
    "\n",
    "    scenario_set = set(all_scenarios)\n",
    "    return scenario_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c502c2b",
   "metadata": {},
   "source": [
    "RGB -> IR\n",
    "\n",
    "기기에 따라 transformation 찾아내기.  \n",
    "transformation은 뭘로 찾을까?  \n",
    "ORB나 SWIFT feature 대신 mediapipe mesh끼리 비교. \n",
    "\n",
    "\n",
    "끝. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f626a489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 JSON files are found\n"
     ]
    }
   ],
   "source": [
    "uid = 71\n",
    "scenario_set = get_all_scenario(uid)\n",
    "\n",
    "for device, ss in scenario_set:\n",
    "    print(\"Device\", device_dict[device], \"Scenario\", ss)\n",
    "    file = scenario.Info(device, base_dir = ddir + f\"{uid:03d}/\",\n",
    "                         scen = ss)\n",
    "    file.vid_dir = vid_dir_base + f\"{file.id}/T1/{file.device_d}/RGB/\"\n",
    "    fn_vid = file.vid_dir + file.fn_vid\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5b419ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_r.release()\n",
    "cap_i.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a849ab68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76edf999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4cbba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68e2eb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 No iris detected\n",
      "IR!\n",
      "IR!\n",
      "32 No iris detected\n",
      "33 No iris detected\n",
      "34 No iris detected\n",
      "IR!\n",
      "54 No iris detected\n",
      "75 No iris detected\n",
      "79 No iris detected\n",
      "83 No iris detected\n",
      "87 No iris detected\n",
      "119 No iris detected\n",
      "121 No iris detected\n",
      "IR!\n",
      "140 No iris detected\n",
      "145 No iris detected\n",
      "160 No iris detected\n",
      "172 No iris detected\n",
      "197 No iris detected\n",
      "IR!\n",
      "211 No iris detected\n",
      "IR!\n",
      "IR!\n",
      "245 No iris detected\n",
      "IR!\n",
      "257 No iris detected\n",
      "IR!\n",
      "275 No iris detected\n",
      "283 No iris detected\n",
      "291 No iris detected\n"
     ]
    }
   ],
   "source": [
    "if (cap_r := file.load_vid('rgb')) and (cap_i := file.load_vid('ir')):\n",
    "    for ff, json in file:\n",
    "        #eye = file.get_eye(json)\n",
    "        #if not hasattr(eye, 'l_iris'):\n",
    "        #    print(ff, \"No iris detected\")\n",
    "        #    continue\n",
    "        # read specific frame \n",
    "        cap_r.set(cv2.CAP_PROP_POS_FRAMES, ff)\n",
    "        ok_rgb, rgb = cap_r.read()\n",
    "        #rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        rgb = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "        cap_i.set(cv2.CAP_PROP_POS_FRAMES, ff)\n",
    "        ok_ir, ir = cap_i.read()\n",
    "        \n",
    "        resi = face_mesh.process(ir)\n",
    "        if resi.multi_face_landmarks:\n",
    "            print(\"IR!\")\n",
    "            resr = face_mesh.process(rgb)\n",
    "            if resr.multi_face_landmarks:\n",
    "                break\n",
    "        continue\n",
    "        \n",
    "        # IR to greyscale 혹은 R 밴드만? \n",
    "        #ir = cv2.cvtColor(ir, cv2.COLOR_BGR2GRAY)\n",
    "        #ir = clahe.apply(ir)\n",
    "        # then do something1111\n",
    "        draw_two_eyes(rgb, eye, fn=f\"{file.id}_{device}_{ff:03d}_rgb.png\")\n",
    "        draw_two_eyes(ir, eye, fn=f\"{file.id}_{device}_{ff:03d}_ir.png\")\n",
    "        \n",
    "else:\n",
    "    print(\"Failed to open both videos\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4708ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resr.multi_face_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a57f6b",
   "metadata": {},
   "source": [
    "# 미디어파이프로 face mesh 찾기\n",
    "\n",
    "face mesh 3D transform 모듈이 있음   \n",
    "카메라 perspective 바꾸는 예제도 있을듯   \n",
    "혹은 3D transform 자체에 대한 예제가 있을 수도.. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22f62551",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5959374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, \n",
    "                            refine_landmarks=True,\n",
    "                            min_detection_confidence=0.5, \n",
    "                            min_tracking_confidence=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65482c07",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_annotated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb_mp_annotated.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36msave_annotated\u001b[0;34m(image, results, fn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_annotated\u001b[39m(image, results, fn):\n\u001b[1;32m      2\u001b[0m     annotated_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m face_landmarks \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_face_landmarks:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_landmarks:\u001b[39m\u001b[38;5;124m'\u001b[39m, face_landmarks)\n\u001b[1;32m      5\u001b[0m         mp_drawing\u001b[38;5;241m.\u001b[39mdraw_landmarks(\n\u001b[1;32m      6\u001b[0m               image\u001b[38;5;241m=\u001b[39mannotated_image,\n\u001b[1;32m      7\u001b[0m               landmark_list\u001b[38;5;241m=\u001b[39mface_landmarks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m               connection_drawing_spec\u001b[38;5;241m=\u001b[39mmp_drawing_styles\n\u001b[1;32m     11\u001b[0m               \u001b[38;5;241m.\u001b[39mget_default_face_mesh_tesselation_style())\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "save_annotated(rgb, resr, fn=\"rgb_mp_annotated.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "767f5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_annotated(image, results, fn):\n",
    "    annotated_image = image.copy()\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        print('face_landmarks:', face_landmarks)\n",
    "        mp_drawing.draw_landmarks(\n",
    "              image=annotated_image,\n",
    "              landmark_list=face_landmarks,\n",
    "              connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "              landmark_drawing_spec=None,\n",
    "              connection_drawing_spec=mp_drawing_styles\n",
    "              .get_default_face_mesh_tesselation_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "              image=annotated_image,\n",
    "              landmark_list=face_landmarks,\n",
    "              connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "              landmark_drawing_spec=None,\n",
    "              connection_drawing_spec=mp_drawing_styles\n",
    "              .get_default_face_mesh_contours_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "              image=annotated_image,\n",
    "              landmark_list=face_landmarks,\n",
    "              connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "              landmark_drawing_spec=None,\n",
    "              connection_drawing_spec=mp_drawing_styles\n",
    "              .get_default_face_mesh_iris_connections_style())\n",
    "        cv2.imwrite(fn, annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affdeb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400534b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4852ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = draw_two_eyes(rgb, eye, fn=\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252500af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Eye' object has no attribute 'l_iris'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_two_eyes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meye\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Displaying the image\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/Work/NIA/nia/nia22/eyes.py:239\u001b[0m, in \u001b[0;36mdraw_two_eyes\u001b[0;34m(image, eye, thickness, alpha)\u001b[0m\n\u001b[1;32m    235\u001b[0m     pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(eyelid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    236\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mpolylines(overlay, [pts],\n\u001b[1;32m    237\u001b[0m                 isClosed, color, thickness)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iris \u001b[38;5;129;01min\u001b[39;00m [\u001b[43meye\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml_iris\u001b[49m, eye\u001b[38;5;241m.\u001b[39mr_iris]:\n\u001b[1;32m    240\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    241\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mellipse(overlay, \n\u001b[1;32m    242\u001b[0m                 (\u001b[38;5;28mint\u001b[39m(iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcx\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcy\u001b[39m\u001b[38;5;124m'\u001b[39m])), \n\u001b[1;32m    243\u001b[0m                 (\u001b[38;5;28mint\u001b[39m(iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrx\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mry\u001b[39m\u001b[38;5;124m'\u001b[39m])),\n\u001b[1;32m    244\u001b[0m                 iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrotate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    245\u001b[0m                 \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m360\u001b[39m, color, thickness)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Eye' object has no attribute 'l_iris'"
     ]
    }
   ],
   "source": [
    "_2475192.jsonimage = draw_two_eyes(rgb, eye)\n",
    "# Displaying the image\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image', image)\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "         \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2f243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f20b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be246b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d099135",
   "metadata": {},
   "source": [
    "## 2. JSON 로딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bffe63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = json.load(open(file._dir + fn_json,\"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a42d00",
   "metadata": {},
   "source": [
    "## 3. RGB / IR 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d90a4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = Eye(anno[\"Annotations\"][\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63954076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e81bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "defa323c",
   "metadata": {},
   "source": [
    "## 4. RGB -> IR 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2026e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052382a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee006d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
