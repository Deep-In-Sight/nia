{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac215b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "61f64f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [100, 150, 200, 250, 300] # 읽고싶은 frame (0부터 시작)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad71fd",
   "metadata": {},
   "source": [
    "원본 영상을 input으로 사용 + 원하는 프레임 정보 혹은\n",
    "뽑아둔 프레임의 이미지가 모인 디렉토리를 input으로 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_video = \"/home/hoseung/Dropbox/DeepInsight/2022/NIA/1Cycle/20220620_213859_.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4824a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(fn_video)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    for iframe in frames: \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, iframe)\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Error? Skipping..\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_org = image.copy()\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # Draw the face mesh annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_tesselation_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_contours_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_iris_connections_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imwrite(f\"frame_{iframe}.png\", cv2.flip(image, 1))\n",
    "        \n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5835bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_xy_points(face_landmarks, iris):\n",
    "    landmarks = face_landmarks.landmark\n",
    "    inds = np.unique(list(iris))\n",
    "    #inds = np.arange(473, 478)\n",
    "    points = [landmarks[p] for p in inds]\n",
    "    arr = np.zeros((len(points),2)) \n",
    "\n",
    "    nx, ny, _ = image.shape\n",
    "    for i, pp in enumerate(points):\n",
    "        arr[i,0] = pp.x * ny\n",
    "        arr[i,1] = pp.y * nx\n",
    "    return arr\n",
    "\n",
    "def get_radius_angle(face_landmarks, detection):\n",
    "    point = get_xy_points(face_landmarks, detection)\n",
    "    center = point[0,:]\n",
    "    x = point[:,0]\n",
    "    y = point[:,1]\n",
    "    ra = np.sqrt((x[1] - x[3])**2 + (y[1]-y[3])**2)/2\n",
    "    rb = np.sqrt((x[2] - x[4])**2 + (y[2]-y[4])**2)/2\n",
    "    angle = np.arctan((y[3] - y[1]) / (x[1] - x[3])) # note that y axis is flipped\n",
    "    angle = np.rad2deg(angle)\n",
    "    return (center, ra, rb, angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df523f7",
   "metadata": {},
   "source": [
    "랜드마크 중 눈과 iris의 index는 아래 문서에서 확인할 수도 있음. \n",
    "\n",
    "https://github.com/tensorflow/tfjs-models/blob/838611c02f51159afdd77469ce67f0e26b7bbb23/face-landmarks-detection/src/mediapipe-facemesh/keypoints.ts\n",
    "\n",
    "참고로, 문서에서의 \"leftEyeIris\"와 mp_face_mesh.FACEMESH_LEFT_EYE는 서로 다른 눈임. \n",
    "하나는 피사체 기준, 하나는 보는 사람 기준인 듯 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af11b611",
   "metadata": {},
   "source": [
    "### 최종적으로 사용하실 값: center, ra, rb, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2a261496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피사체의 왼눈: center, ra, rb, angle\n",
      " (array([1487.15858459,  464.30525064]), 37.52503595163705, 28.34770778861998, -3.5628922659378297)\n",
      "피사체의 오른눈: center, ra, rb, angle\n",
      " (array([1138.09593201,  438.00797224]), 34.33496973960113, 27.700583469755063, 2.71608687764671)\n"
     ]
    }
   ],
   "source": [
    "print(\"피사체의 왼눈: center, ra, rb, angle\\n\", \n",
    "      get_radius_angle(face_landmarks, [473, 474, 475, 476, 477]))\n",
    "print(\"피사체의 오른눈: center, ra, rb, angle\\n\",\n",
    "      get_radius_angle(face_landmarks, [468, 469, 470, 471, 472]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595063a",
   "metadata": {},
   "source": [
    "테스트용 그림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9782f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots(subplot_kw={'aspect': 'equal'})\n",
    "fig.set_size_inches(16,9)\n",
    "\n",
    "# 피사체의 왼쪽 눈\n",
    "center, ra, rb, angle = get_radius_angle(face_landmarks, ind_rightEyeIris)\n",
    "ellipse1 = Ellipse(center, 2*ra,2*rb, angle=angle, alpha=0.5,\n",
    "                  facecolor='none', edgecolor=\"red\", lw=3)\n",
    "ax.add_artist(ellipse1)\n",
    "\n",
    "# 공막\n",
    "p_left_eyes = get_xy_points(face_landmarks, mp_face_mesh.FACEMESH_LEFT_EYE)\n",
    "plt.scatter(p_left_eyes[:,0], p_left_eyes[:,1], s=10)\n",
    "\n",
    "\n",
    "#피사체의 오른쪽 눈\n",
    "center, ra, rb, angle = get_radius_angle(face_landmarks, ind_leftEyeIris)\n",
    "ellipse2 = Ellipse(center, 2*ra,2*rb, angle=angle, alpha=0.5,\n",
    "                  facecolor='none', edgecolor=\"red\", lw=3)\n",
    "ax.add_artist(ellipse2)\n",
    "\n",
    "p_right_eyes = get_xy_points(face_landmarks, mp_face_mesh.FACEMESH_RIGHT_EYE)\n",
    "plt.scatter(p_right_eyes[:,0], p_right_eyes[:,1], s=10)\n",
    "\n",
    "\n",
    "ax.imshow(image_org)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
